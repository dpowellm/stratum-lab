{"event_id": "evt_400a688d56a14fd7", "timestamp_ns": 1771373097240727269, "run_id": "9094b6ec-20c8-4117-a1a7-1e87c41f37a6", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_e05dd7a6eb544544", "timestamp_ns": 1771373121400320776, "run_id": "9094b6ec-20c8-4117-a1a7-1e87c41f37a6", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_4dc6ede6e4404358", "timestamp_ns": 1771373143085978779, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_ce8e51f4090a41c5", "timestamp_ns": 1771373281713362494, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_0ab456bbc90949e7", "timestamp_ns": 1771373291382971975, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "gpt-3.5-turbo", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": true, "message_count": 1, "has_tools": false, "last_user_message_preview": "You are a router agent for a data analytics system. Analyze the user's query and determine which agent should handle it.\n\nQuery: \"Hello! I'm new here.\"\n\nRoute to:\n- 'pandas': For data analysis, statis", "last_user_message_hash": "33d221beb05d9dfe"}, "stack_depth": 0}
{"event_id": "evt_acc7411dbb2a4b0d", "timestamp_ns": 1771373291942679916, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "latency_ms": 559.35, "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "error_type": null, "active_node_stack": ["openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417"], "output_hash": null, "output_type": "null", "output_size_bytes": 0, "output_preview": "", "output_structure": null, "classification_fields": null}, "parent_event_id": "evt_0ab456bbc90949e7", "stack_depth": 0}
{"event_id": "evt_d02fdd41127149f1", "timestamp_ns": 1771373292031944566, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "gpt-3.5-turbo", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": true, "message_count": 1, "has_tools": false, "last_user_message_preview": "You are a router agent for a data analytics system. Analyze the user's query and determine which agent should handle it.\n\nQuery: \"What can you do with CSV files?\"\n\nRoute to:\n- 'pandas': For data analy", "last_user_message_hash": "caaac14b8952efcd"}, "stack_depth": 0}
{"event_id": "evt_f08487edfaba44da", "timestamp_ns": 1771373292223171555, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "latency_ms": 190.93, "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "error_type": null, "active_node_stack": ["openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417"], "output_hash": null, "output_type": "null", "output_size_bytes": 0, "output_preview": "", "output_structure": null, "classification_fields": null}, "parent_event_id": "evt_d02fdd41127149f1", "stack_depth": 0}
{"event_id": "evt_24dddda616b34571", "timestamp_ns": 1771373292230505540, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "gpt-3.5-turbo", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": true, "message_count": 1, "has_tools": false, "last_user_message_preview": "You are a conversation memory manager for a data analytics assistant. Your role is to:\n\n1. Maintain context from previous messages in the conversation\n2. Provide relevant context to help other agents ", "last_user_message_hash": "6bb7aedafcc0d9a6"}, "stack_depth": 0}
{"event_id": "evt_ee43eb2535354e66", "timestamp_ns": 1771373296819036094, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "latency_ms": 4585.22, "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "error_type": null, "active_node_stack": ["openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417"], "output_hash": null, "output_type": "null", "output_size_bytes": 0, "output_preview": "", "output_structure": null, "classification_fields": null}, "parent_event_id": "evt_24dddda616b34571", "stack_depth": 0}
{"event_id": "evt_0ac494592d3a460e", "timestamp_ns": 1771373296838914265, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "gpt-3.5-turbo", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": true, "message_count": 1, "has_tools": false, "last_user_message_preview": "You are a router agent for a data analytics system. Analyze the user's query and determine which agent should handle it.\n\nQuery: \"Thanks! How do I get started?\"\n\nRoute to:\n- 'pandas': For data analysi", "last_user_message_hash": "c7b928af0384a779"}, "stack_depth": 0}
{"event_id": "evt_f62104ea58d24706", "timestamp_ns": 1771373297232339381, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "latency_ms": 393.14, "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "error_type": null, "active_node_stack": ["openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417"], "output_hash": null, "output_type": "null", "output_size_bytes": 0, "output_preview": "", "output_structure": null, "classification_fields": null}, "parent_event_id": "evt_0ac494592d3a460e", "stack_depth": 0}
{"event_id": "evt_5c8804e8604f4fb3", "timestamp_ns": 1771373297248242778, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "gpt-3.5-turbo", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": true, "message_count": 1, "has_tools": false, "last_user_message_preview": "You are a conversation memory manager for a data analytics assistant. Your role is to:\n\n1. Maintain context from previous messages in the conversation\n2. Provide relevant context to help other agents ", "last_user_message_hash": "6bb7aedafcc0d9a6"}, "stack_depth": 0}
{"event_id": "evt_5df4e00f23594d4a", "timestamp_ns": 1771373302800048560, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "latency_ms": 5551.51, "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "error_type": null, "active_node_stack": ["openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417"], "output_hash": null, "output_type": "null", "output_size_bytes": 0, "output_preview": "", "output_structure": null, "classification_fields": null}, "parent_event_id": "evt_5c8804e8604f4fb3", "stack_depth": 0}
{"event_id": "evt_e3ec321fc7e0462a", "timestamp_ns": 1771373326913560038, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_8fd9787e167744e8", "timestamp_ns": 1771373326914492763, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "file.read", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/stderr.log:0", "node_name": "/app/output/stderr.log"}, "payload": {"path": "/app/output/stderr.log", "mode": "r"}, "stack_depth": 0}
{"event_id": "evt_dd3bb2cf412f4f93", "timestamp_ns": 1771373326917902894, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "file.read", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/tier2_stderr.log:0", "node_name": "/app/output/tier2_stderr.log"}, "payload": {"path": "/app/output/tier2_stderr.log", "mode": "r"}, "stack_depth": 0}
{"event_id": "evt_b4776ebdb71a4646", "timestamp_ns": 1771373326918062114, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "file.write", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/status.json:0", "node_name": "/app/output/status.json"}, "payload": {"path": "/app/output/status.json", "mode": "w"}, "stack_depth": 0}
{"event_id": "evt_ca9b5f1cf0ec442a", "timestamp_ns": 1771373350825779630, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_dc7cf9541982462f", "timestamp_ns": 1771373350826877713, "run_id": "cdf2246d9b3b4f66", "repo_id": "https://github.com/abh2050/langgraph_data_analytics_agents", "framework": "auto", "event_type": "file.write", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/run_metadata_1.json:0", "node_name": "/app/output/run_metadata_1.json"}, "payload": {"path": "/app/output/run_metadata_1.json", "mode": "w"}, "stack_depth": 0}
