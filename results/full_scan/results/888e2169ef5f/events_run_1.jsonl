{"event_id": "evt_eb5d94cdb6c7408d", "timestamp_ns": 1771377997654728711, "run_id": "cf0ff59c-27e0-4552-9344-1c04c692f523", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_a40576d3eff64523", "timestamp_ns": 1771378009471710084, "run_id": "cf0ff59c-27e0-4552-9344-1c04c692f523", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_86597f2713494719", "timestamp_ns": 1771378020502553878, "run_id": "b14be374f59c42d9", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_566641279ef54956", "timestamp_ns": 1771378058045469474, "run_id": "b14be374f59c42d9", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_84f5565f27e742ae", "timestamp_ns": 1771378058119107202, "run_id": "b14be374f59c42d9", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "error.occurred", "source_node": {"node_type": "agent", "node_id": "generic:exception:/usr/local/lib/python3.11/site-packages/langchain/chat_models/base.py:123", "node_name": "unhandled_exception"}, "payload": {"error_type": "ImportError", "error_message": "Initializing ChatAnthropic requires the langchain-anthropic package. Please install it with `pip install langchain-anthropic`", "traceback_tail": "pic:claude-3-5-sonnet-latest\")\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/langchain/chat_models/base.py\", line 464, in init_chat_model\n    return _init_chat_model_helper(\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/langchain/chat_models/base.py\", line 487, in _init_chat_model_helper\n    creator_func = _get_chat_model_creator(model_provider)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/langchain/chat_models/base.py\", line 154, in _get_chat_model_creator\n    module = _import_module(pkg, class_name)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/langchain/chat_models/base.py\", line 123, in _import_module\n    raise ImportError(msg) from e\nImportError: Initializing ChatAnthropic requires the langchain-anthropic package. Please install it with `pip install langchain-anthropic`\n", "file": "/usr/local/lib/python3.11/site-packages/langchain/chat_models/base.py", "line": 123}, "stack_depth": 0}
{"event_id": "evt_691f637410614031", "timestamp_ns": 1771378070781817078, "run_id": "b14be374f59c42d9", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_908960ecbcf04280", "timestamp_ns": 1771378088393455047, "run_id": "b14be374f59c42d9", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_1e5f1163e5fb4301", "timestamp_ns": 1771378088912657407, "run_id": "b14be374f59c42d9", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "anthropic:Messages:/usr/local/lib/python3.11/site-packages/langchain_anthropic/chat_models.py:1396", "node_name": "anthropic.messages.create"}, "payload": {"model_requested": "claude-3-5-sonnet-latest", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": true, "message_count": 1, "has_tools": false, "redirected_to": "vllm_openai_compat"}, "stack_depth": 0}
{"event_id": "evt_3d429975fab74f23", "timestamp_ns": 1771378088980963609, "run_id": "b14be374f59c42d9", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/opt/stratum_patcher/anthropic_patch.py:415", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": false, "message_count": 1, "has_tools": false, "last_user_message_preview": "What is LangGraph and how does it work?", "last_user_message_hash": "95693fc251a8337d"}, "stack_depth": 0}
{"event_id": "evt_dcdbfb185155432f", "timestamp_ns": 1771378089454127254, "run_id": "b14be374f59c42d9", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/opt/stratum_patcher/anthropic_patch.py:415", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "latency_ms": 472.92, "error": "Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 4096 tokens and your request has 13 input tokens (4096 > 4096 - 13). (parameter=max_tokens, value=4096)\", 'type': 'BadRequestError', 'param': 'max_tokens', 'code': 400}}", "error_type": "runtime_error", "active_node_stack": ["openai:ChatCompletion:/opt/stratum_patcher/anthropic_patch.py:415"]}, "parent_event_id": "evt_3d429975fab74f23", "stack_depth": 0}
{"event_id": "evt_7593e741e4874654", "timestamp_ns": 1771378089454367216, "run_id": "b14be374f59c42d9", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "anthropic:Messages:/usr/local/lib/python3.11/site-packages/langchain_anthropic/chat_models.py:1396", "node_name": "anthropic.messages.create"}, "payload": {"model_requested": "claude-3-5-sonnet-latest", "latency_ms": 541.51, "redirected_to": "vllm_openai_compat", "error": "Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 4096 tokens and your request has 13 input tokens (4096 > 4096 - 13). (parameter=max_tokens, value=4096)\", 'type': 'BadRequestError', 'param': 'max_tokens', 'code': 400}}"}, "parent_event_id": "evt_1e5f1163e5fb4301", "stack_depth": 0}
{"event_id": "evt_94344ac989c94719", "timestamp_ns": 1771378089468227301, "run_id": "b14be374f59c42d9", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "error.occurred", "source_node": {"node_type": "agent", "node_id": "generic:exception:/usr/local/lib/python3.11/site-packages/openai/_base_client.py:1070", "node_name": "unhandled_exception"}, "payload": {"error_type": "BadRequestError", "error_message": "Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 4096 tokens and your request has 13 input tokens (4096 > 4096 - 13). (parameter=max_tokens, value=4096)\", 'type': 'BadRequestError', 'param': 'max_tokens', 'code': 400}}", "traceback_tail": "ython3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1192, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1297, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1070, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 4096 tokens and your request has 13 input tokens (4096 > 4096 - 13). (parameter=max_tokens, value=4096)\", 'type': 'BadRequestError', 'param': 'max_tokens', 'code': 400}}\nDuring task with name 'chatbot' and id 'aba76635-66ef-c2a9-96c7-95b98365897a'\n", "file": "/usr/local/lib/python3.11/site-packages/openai/_base_client.py", "line": 1070}, "stack_depth": 0}
{"event_id": "evt_a6938ffee1b34d78", "timestamp_ns": 1771378102702154423, "run_id": "b14be374f59c42d9", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_3346ff4a5066490d", "timestamp_ns": 1771378102709025987, "run_id": "b14be374f59c42d9", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "file.read", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/stderr.log:0", "node_name": "/app/output/stderr.log"}, "payload": {"path": "/app/output/stderr.log", "mode": "r"}, "stack_depth": 0}
{"event_id": "evt_6e2bc4ca1b724409", "timestamp_ns": 1771378102709362505, "run_id": "b14be374f59c42d9", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "file.write", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/status.json:0", "node_name": "/app/output/status.json"}, "payload": {"path": "/app/output/status.json", "mode": "w"}, "stack_depth": 0}
{"event_id": "evt_3c68af46e91b4c22", "timestamp_ns": 1771378115032054121, "run_id": "b14be374f59c42d9", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_d246be9a35c646bb", "timestamp_ns": 1771378115037158941, "run_id": "b14be374f59c42d9", "repo_id": "https://github.com/Mar-Issah/langchain-agents", "framework": "auto", "event_type": "file.write", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/run_metadata_1.json:0", "node_name": "/app/output/run_metadata_1.json"}, "payload": {"path": "/app/output/run_metadata_1.json", "mode": "w"}, "stack_depth": 0}
