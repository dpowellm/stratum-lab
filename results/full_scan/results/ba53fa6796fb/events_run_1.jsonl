{"event_id": "evt_91bde99ce61f42ce", "timestamp_ns": 1771373377307293130, "run_id": "9094b6ec-20c8-4117-a1a7-1e87c41f37a6", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_0986e68b369b404b", "timestamp_ns": 1771373399492291465, "run_id": "9094b6ec-20c8-4117-a1a7-1e87c41f37a6", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_5ed3b164e6674ebf", "timestamp_ns": 1771373424392424672, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_425be6f015e04933", "timestamp_ns": 1771373569139481816, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_0093823d08de4f5f", "timestamp_ns": 1771373577765951719, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "gpt-3.5-turbo", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": true, "message_count": 1, "has_tools": false, "last_user_message_preview": "You are a router agent for a data analytics system. Analyze the user's query and determine which agent should handle it.\n\nQuery: \"Hello! I'm new here.\"\n\nRoute to:\n- 'pandas': For data analysis, statis", "last_user_message_hash": "33d221beb05d9dfe"}, "stack_depth": 0}
{"event_id": "evt_6170c750e3ad4b58", "timestamp_ns": 1771373578995383923, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "latency_ms": 1229.13, "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "error_type": null, "active_node_stack": ["openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417"], "output_hash": null, "output_type": "null", "output_size_bytes": 0, "output_preview": "", "output_structure": null, "classification_fields": null}, "parent_event_id": "evt_0093823d08de4f5f", "stack_depth": 0}
{"event_id": "evt_950e9fb4724b4dba", "timestamp_ns": 1771373579053412403, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "gpt-3.5-turbo", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": true, "message_count": 1, "has_tools": false, "last_user_message_preview": "You are a router agent for a data analytics system. Analyze the user's query and determine which agent should handle it.\n\nQuery: \"What can you do with CSV files?\"\n\nRoute to:\n- 'pandas': For data analy", "last_user_message_hash": "caaac14b8952efcd"}, "stack_depth": 0}
{"event_id": "evt_b3f7369cae0c4416", "timestamp_ns": 1771373579233989858, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "latency_ms": 180.28, "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "error_type": null, "active_node_stack": ["openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417"], "output_hash": null, "output_type": "null", "output_size_bytes": 0, "output_preview": "", "output_structure": null, "classification_fields": null}, "parent_event_id": "evt_950e9fb4724b4dba", "stack_depth": 0}
{"event_id": "evt_bfd89faf83994ebc", "timestamp_ns": 1771373579244291716, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "gpt-3.5-turbo", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": true, "message_count": 1, "has_tools": false, "last_user_message_preview": "You are a conversation memory manager for a data analytics assistant. Your role is to:\n\n1. Maintain context from previous messages in the conversation\n2. Provide relevant context to help other agents ", "last_user_message_hash": "6bb7aedafcc0d9a6"}, "stack_depth": 0}
{"event_id": "evt_b8019490bea34797", "timestamp_ns": 1771373583817618246, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "latency_ms": 4573.02, "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "error_type": null, "active_node_stack": ["openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417"], "output_hash": null, "output_type": "null", "output_size_bytes": 0, "output_preview": "", "output_structure": null, "classification_fields": null}, "parent_event_id": "evt_bfd89faf83994ebc", "stack_depth": 0}
{"event_id": "evt_02116c11c7d74ac8", "timestamp_ns": 1771373583835926411, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "gpt-3.5-turbo", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": true, "message_count": 1, "has_tools": false, "last_user_message_preview": "You are a router agent for a data analytics system. Analyze the user's query and determine which agent should handle it.\n\nQuery: \"Thanks! How do I get started?\"\n\nRoute to:\n- 'pandas': For data analysi", "last_user_message_hash": "c7b928af0384a779"}, "stack_depth": 0}
{"event_id": "evt_b2f8136bdeda4d5e", "timestamp_ns": 1771373584028520279, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "latency_ms": 192.13, "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "error_type": null, "active_node_stack": ["openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417"], "output_hash": null, "output_type": "null", "output_size_bytes": 0, "output_preview": "", "output_structure": null, "classification_fields": null}, "parent_event_id": "evt_02116c11c7d74ac8", "stack_depth": 0}
{"event_id": "evt_f74aaa7dcd884c40", "timestamp_ns": 1771373584045328088, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "gpt-3.5-turbo", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": true, "message_count": 1, "has_tools": false, "last_user_message_preview": "You are a conversation memory manager for a data analytics assistant. Your role is to:\n\n1. Maintain context from previous messages in the conversation\n2. Provide relevant context to help other agents ", "last_user_message_hash": "6bb7aedafcc0d9a6"}, "stack_depth": 0}
{"event_id": "evt_8f5ca096b62147d5", "timestamp_ns": 1771373589661952614, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "latency_ms": 5616.32, "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "error_type": null, "active_node_stack": ["openai:ChatCompletion:/usr/local/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1417"], "output_hash": null, "output_type": "null", "output_size_bytes": 0, "output_preview": "", "output_structure": null, "classification_fields": null}, "parent_event_id": "evt_f74aaa7dcd884c40", "stack_depth": 0}
{"event_id": "evt_5930fbe31b9342f8", "timestamp_ns": 1771373612682956193, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_0b92472d124649b5", "timestamp_ns": 1771373612683795648, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "file.read", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/stderr.log:0", "node_name": "/app/output/stderr.log"}, "payload": {"path": "/app/output/stderr.log", "mode": "r"}, "stack_depth": 0}
{"event_id": "evt_2b5badf70ced4bfe", "timestamp_ns": 1771373612684020184, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "file.read", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/tier2_stderr.log:0", "node_name": "/app/output/tier2_stderr.log"}, "payload": {"path": "/app/output/tier2_stderr.log", "mode": "r"}, "stack_depth": 0}
{"event_id": "evt_b3bf90aee11449ea", "timestamp_ns": 1771373612684135694, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "file.write", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/status.json:0", "node_name": "/app/output/status.json"}, "payload": {"path": "/app/output/status.json", "mode": "w"}, "stack_depth": 0}
{"event_id": "evt_c2a15b67ef0d45fd", "timestamp_ns": 1771373635783130071, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_577684fe8b024556", "timestamp_ns": 1771373635784229911, "run_id": "6890bced20414df2", "repo_id": "https://github.com/Saad096/langgraph_data_analytics_multi_agents_app", "framework": "auto", "event_type": "file.write", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/run_metadata_1.json:0", "node_name": "/app/output/run_metadata_1.json"}, "payload": {"path": "/app/output/run_metadata_1.json", "mode": "w"}, "stack_depth": 0}
