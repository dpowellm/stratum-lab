{"event_id": "evt_adeca161e2074fc3", "timestamp_ns": 1771343043103633809, "run_id": "8d3e917d-5ce2-4913-910a-1fb1677d0ae2", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_f7052e8eeb0048f0", "timestamp_ns": 1771343064533218360, "run_id": "8d3e917d-5ce2-4913-910a-1fb1677d0ae2", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_96ddf80e354e4cbb", "timestamp_ns": 1771343085896186106, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_d0a416341fc247e8", "timestamp_ns": 1771343108742353026, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_a30cade9c491415e", "timestamp_ns": 1771343155755387985, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_c51d65057fc24c5a", "timestamp_ns": 1771343179444815881, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_355c28532a3648dc", "timestamp_ns": 1771343221481383825, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_ae5accbed5964fae", "timestamp_ns": 1771343221488630764, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "error.occurred", "source_node": {"node_type": "agent", "node_id": "generic:exception:/tmp/repo/langgraph_examples/deep_research_agent/deep_research_simplified.py:28", "node_name": "unhandled_exception"}, "payload": {"error_type": "ModuleNotFoundError", "error_message": "No module named 'tavily'", "traceback_tail": "Traceback (most recent call last):\n  File \"/tmp/repo/langgraph_examples/deep_research_agent/deep_research_simplified.py\", line 28, in <module>\n    from tavily import TavilyClient\nModuleNotFoundError: No module named 'tavily'\n", "file": "/tmp/repo/langgraph_examples/deep_research_agent/deep_research_simplified.py", "line": 28}, "stack_depth": 0}
{"event_id": "evt_ea2ab9b786ff412d", "timestamp_ns": 1771343247101271537, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_ebc8c9eadf4243df", "timestamp_ns": 1771343279557531274, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_1c599fd478d94658", "timestamp_ns": 1771343279571010834, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "error.occurred", "source_node": {"node_type": "agent", "node_id": "generic:exception:/tmp/repo/langgraph_examples/deep_research_agent/deep_research_simplified.py:32", "node_name": "unhandled_exception"}, "payload": {"error_type": "ModuleNotFoundError", "error_message": "No module named 'deepagents'", "traceback_tail": "Traceback (most recent call last):\n  File \"/tmp/repo/langgraph_examples/deep_research_agent/deep_research_simplified.py\", line 32, in <module>\n    from deepagents import create_deep_agent\nModuleNotFoundError: No module named 'deepagents'\n", "file": "/tmp/repo/langgraph_examples/deep_research_agent/deep_research_simplified.py", "line": 32}, "stack_depth": 0}
{"event_id": "evt_1c3d826ad3dd476d", "timestamp_ns": 1771343304894748421, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_caac8b79763d4559", "timestamp_ns": 1771343348631239518, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_e3b3c513e545404c", "timestamp_ns": 1771343351872969603, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "anthropic:Messages:/usr/local/lib/python3.11/site-packages/langchain_anthropic/chat_models.py:1396", "node_name": "anthropic.messages.create"}, "payload": {"model_requested": "claude-sonnet-4-5-20250929", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": true, "message_count": 1, "has_tools": true, "redirected_to": "vllm_openai_compat"}, "stack_depth": 0}
{"event_id": "evt_150e1e3650044eba", "timestamp_ns": 1771343351936752728, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/opt/stratum_patcher/anthropic_patch.py:415", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": false, "message_count": 2, "has_tools": true, "system_prompt_preview": "You are a research coordinator.\n\nFor complex research queries, delegate to the deep-researcher subagent.\nFor simple questions, answer directly using internet_search.\n\nWhen delegating research:\n1. Pass", "system_prompt_hash": "e994583a1f946c2f", "last_user_message_preview": "\n    Research AI-Powered Security Operations Centers (SOC).\n    I want to understand:\n    - Current landscape and key players\n    - Technology approaches and architectures\n    - Startup funding and ma", "last_user_message_hash": "f11fa3a968281e32"}, "stack_depth": 0}
{"event_id": "evt_df4b70bb735748fa", "timestamp_ns": 1771343352595699049, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/opt/stratum_patcher/anthropic_patch.py:415", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "latency_ms": 658.68, "error": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 4096 tokens. However, your request has 6058 input tokens. Please reduce the length of the input messages. (parameter=input_tokens, value=6058)\", 'type': 'BadRequestError', 'param': 'input_tokens', 'code': 400}}", "error_type": "runtime_error", "active_node_stack": ["openai:ChatCompletion:/opt/stratum_patcher/anthropic_patch.py:415"]}, "parent_event_id": "evt_150e1e3650044eba", "stack_depth": 0}
{"event_id": "evt_b893d5e6b85941d4", "timestamp_ns": 1771343352595941754, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "anthropic:Messages:/usr/local/lib/python3.11/site-packages/langchain_anthropic/chat_models.py:1396", "node_name": "anthropic.messages.create"}, "payload": {"model_requested": "claude-sonnet-4-5-20250929", "latency_ms": 722.78, "redirected_to": "vllm_openai_compat", "error": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 4096 tokens. However, your request has 6058 input tokens. Please reduce the length of the input messages. (parameter=input_tokens, value=6058)\", 'type': 'BadRequestError', 'param': 'input_tokens', 'code': 400}}"}, "parent_event_id": "evt_e3b3c513e545404c", "stack_depth": 0}
{"event_id": "evt_f5bc48f68e2c47a1", "timestamp_ns": 1771343352613291123, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "error.occurred", "source_node": {"node_type": "agent", "node_id": "generic:exception:/usr/local/lib/python3.11/site-packages/openai/_base_client.py:1070", "node_name": "unhandled_exception"}, "payload": {"error_type": "BadRequestError", "error_message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 4096 tokens. However, your request has 6058 input tokens. Please reduce the length of the input messages. (parameter=input_tokens, value=6058)\", 'type': 'BadRequestError', 'param': 'input_tokens', 'code': 400}}", "traceback_tail": "ile \"/usr/local/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1192, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1297, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1070, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 4096 tokens. However, your request has 6058 input tokens. Please reduce the length of the input messages. (parameter=input_tokens, value=6058)\", 'type': 'BadRequestError', 'param': 'input_tokens', 'code': 400}}\nDuring task with name 'model' and id 'fff786d5-f5dd-702b-0fee-752f52baf666'\n", "file": "/usr/local/lib/python3.11/site-packages/openai/_base_client.py", "line": 1070}, "stack_depth": 0}
{"event_id": "evt_f27d3830607b4cbf", "timestamp_ns": 1771343375654106231, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_595753191f494787", "timestamp_ns": 1771343375656983574, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "file.read", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/stderr.log:0", "node_name": "/app/output/stderr.log"}, "payload": {"path": "/app/output/stderr.log", "mode": "r"}, "stack_depth": 0}
{"event_id": "evt_ed2a9db9ab4a4276", "timestamp_ns": 1771343375657279179, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "file.write", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/status.json:0", "node_name": "/app/output/status.json"}, "payload": {"path": "/app/output/status.json", "mode": "w"}, "stack_depth": 0}
{"event_id": "evt_4949fd93a5084bbb", "timestamp_ns": 1771343402878354403, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_eb27ab0f4acc4435", "timestamp_ns": 1771343402879518392, "run_id": "b5509f20a81147ac", "repo_id": "https://github.com/aimanyounises1/LangChainTutorial", "framework": "auto", "event_type": "file.write", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/run_metadata_1.json:0", "node_name": "/app/output/run_metadata_1.json"}, "payload": {"path": "/app/output/run_metadata_1.json", "mode": "w"}, "stack_depth": 0}
