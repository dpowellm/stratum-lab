{"event_id": "evt_8fad09bdd40548c8", "timestamp_ns": 1771316501487645356, "run_id": "8d3e917d-5ce2-4913-910a-1fb1677d0ae2", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_6d246da674f9440a", "timestamp_ns": 1771316528976234455, "run_id": "8d3e917d-5ce2-4913-910a-1fb1677d0ae2", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_02b920791e004fde", "timestamp_ns": 1771316553888767081, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_45578edb28464069", "timestamp_ns": 1771316590139043371, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_70a6a59e3fa647f7", "timestamp_ns": 1771316617480059494, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_efce8c96e6104215", "timestamp_ns": 1771316688570403134, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_b72042f7696a45fd", "timestamp_ns": 1771316806809631677, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_fd59847cd1a74492", "timestamp_ns": 1771316861444090740, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_4894f44fadf34b3d", "timestamp_ns": 1771316863422395465, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "anthropic:Messages:/usr/local/lib/python3.11/site-packages/langchain_anthropic/chat_models.py:1396", "node_name": "anthropic.messages.create"}, "payload": {"model_requested": "claude-3-haiku-20240307", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": true, "message_count": 1, "has_tools": true, "redirected_to": "vllm_openai_compat"}, "stack_depth": 0}
{"event_id": "evt_9482ee8fb64d491a", "timestamp_ns": 1771316863480281070, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "llm.call_start", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/opt/stratum_patcher/anthropic_patch.py:415", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "model_actual": "mistralai/Mistral-7B-Instruct-v0.3", "model_mapped": false, "message_count": 2, "has_tools": true, "system_prompt_preview": "You are an expert software engineer. You have access to the filesystem. Execute the user's requests step by step.", "system_prompt_hash": "3530d45564185262", "last_user_message_preview": "\n1. Create a directory named 'my_project_v2'.\n2. Inside 'my_project_v2', create a file named 'hello.py' with content 'print(\"Hello form Gemini CLI\")'.\n3. Run 'hello.py' and show me the output.\n", "last_user_message_hash": "112f9c7ba209a33e"}, "stack_depth": 0}
{"event_id": "evt_d363818f4f1e46d2", "timestamp_ns": 1771316863979727884, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "openai:ChatCompletion:/opt/stratum_patcher/anthropic_patch.py:415", "node_name": "openai.chat.completions.create"}, "payload": {"model_requested": "mistralai/Mistral-7B-Instruct-v0.3", "latency_ms": 499.14, "error": "Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 4096 tokens and your request has 447 input tokens (4096 > 4096 - 447). (parameter=max_tokens, value=4096)\", 'type': 'BadRequestError', 'param': 'max_tokens', 'code': 400}}", "error_type": "runtime_error", "active_node_stack": ["openai:ChatCompletion:/opt/stratum_patcher/anthropic_patch.py:415"]}, "parent_event_id": "evt_9482ee8fb64d491a", "stack_depth": 0}
{"event_id": "evt_192be11f4e794c33", "timestamp_ns": 1771316863980071497, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "llm.call_end", "source_node": {"node_type": "capability", "node_id": "anthropic:Messages:/usr/local/lib/python3.11/site-packages/langchain_anthropic/chat_models.py:1396", "node_name": "anthropic.messages.create"}, "payload": {"model_requested": "claude-3-haiku-20240307", "latency_ms": 553.34, "redirected_to": "vllm_openai_compat", "error": "Error code: 400 - {'error': {'message': \"'max_tokens' or 'max_completion_tokens' is too large: 4096. This model's maximum context length is 4096 tokens and your request has 447 input tokens (4096 > 4096 - 447). (parameter=max_tokens, value=4096)\", 'type': 'BadRequestError', 'param': 'max_tokens', 'code': 400}}"}, "parent_event_id": "evt_4894f44fadf34b3d", "stack_depth": 0}
{"event_id": "evt_1ed1170657e840f5", "timestamp_ns": 1771316900652475781, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_cf3db8d55c184643", "timestamp_ns": 1771316900653626352, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "file.read", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/stderr.log:0", "node_name": "/app/output/stderr.log"}, "payload": {"path": "/app/output/stderr.log", "mode": "r"}, "stack_depth": 0}
{"event_id": "evt_b020631115e945f4", "timestamp_ns": 1771316900653868865, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "file.read", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/tier2_stderr.log:0", "node_name": "/app/output/tier2_stderr.log"}, "payload": {"path": "/app/output/tier2_stderr.log", "mode": "r"}, "stack_depth": 0}
{"event_id": "evt_896e98473df24b52", "timestamp_ns": 1771316900654082017, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "file.write", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/status.json:0", "node_name": "/app/output/status.json"}, "payload": {"path": "/app/output/status.json", "mode": "w"}, "stack_depth": 0}
{"event_id": "evt_f527992cff164d4c", "timestamp_ns": 1771316937103025787, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "patcher.status", "payload": {"patches": {"generic": "ok", "openai": "ok", "anthropic": "ok", "crewai": "ok", "langgraph": "ok", "autogen": "ok", "litellm": "ok"}, "patches_ok": 7, "patches_skipped": 0}, "stack_depth": 0}
{"event_id": "evt_f1e252410df04e0b", "timestamp_ns": 1771316937106100926, "run_id": "baf3c427f9e1443b", "repo_id": "https://github.com/nitishkthakur/Langchain", "framework": "auto", "event_type": "file.write", "source_node": {"node_type": "data_store", "node_id": "generic:file_io:/app/output/run_metadata_1.json:0", "node_name": "/app/output/run_metadata_1.json"}, "payload": {"path": "/app/output/run_metadata_1.json", "mode": "w"}, "stack_depth": 0}
