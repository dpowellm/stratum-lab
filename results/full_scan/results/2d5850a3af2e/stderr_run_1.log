Traceback (most recent call last):
  File "/tmp/repo/src/llm_client.py", line 130, in generate
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://api.openai.com/v1/chat/completions

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/tmp/repo/src/llm_client.py", line 215, in <module>
    response2 = llm2.generate("Hello, how are you?")
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/tmp/repo/src/llm_client.py", line 143, in generate
    raise RuntimeError(f"LLM API request failed: {e}")
RuntimeError: LLM API request failed: 401 Client Error: Unauthorized for url: https://api.openai.com/v1/chat/completions
