"""Sherlock-inspired topology vulnerability scoring for stratum-lab.

Computes per-node vulnerability scores based on graph position, fan-in/fan-out,
betweenness centrality, error propagation reach, and defensive pattern mitigation.
"""
from __future__ import annotations


def classify_position(node_id: str, sources: set[str], targets: set[str]) -> str:
    """Classify a node's position in the graph topology."""
    is_initial = node_id not in targets and node_id in sources
    is_terminal = node_id in targets and node_id not in sources
    is_intermediate = node_id in targets and node_id in sources

    if is_initial:
        return "initial"
    elif is_terminal:
        return "terminal"
    elif is_intermediate:
        return "intermediate"
    return "isolated"


def compute_downstream_reach(start_node: str, edges: list[tuple[str, str]]) -> int:
    """BFS to count nodes reachable downstream from start_node."""
    adjacency: dict[str, list[str]] = {}
    for src, tgt in edges:
        if src not in adjacency:
            adjacency[src] = []
        adjacency[src].append(tgt)

    visited: set[str] = set()
    queue = [start_node]
    while queue:
        node = queue.pop(0)
        for neighbor in adjacency.get(node, []):
            if neighbor not in visited and neighbor != start_node:
                visited.add(neighbor)
                queue.append(neighbor)
    return len(visited)


def check_node_defenses(node_id: str, defensive_patterns: dict) -> dict:
    """Check if a node has defensive patterns using role-name matching."""
    parts = node_id.split(":")
    role_name = parts[1] if len(parts) > 1 else node_id
    role_lower = role_name.lower()

    defenses = {
        "has_timeout": False,
        "has_output_validation": False,
        "has_error_handling": False,
        "has_input_sanitization": False,
        "has_prompt_constraints": False,
        "defense_count": 0,
    }

    for pattern in defensive_patterns.get("patterns", []):
        file_path = pattern.get("file_path", "").lower()
        category = pattern.get("pattern_category", "")
        near_boundary = pattern.get("near_delegation_boundary", False)

        if role_lower in file_path or near_boundary:
            if category == "timeout_iteration_guards":
                defenses["has_timeout"] = True
            elif category == "output_validation":
                defenses["has_output_validation"] = True
            elif category == "exception_handling_topology":
                defenses["has_error_handling"] = True
            elif category == "input_sanitization":
                defenses["has_input_sanitization"] = True
            elif category == "prompt_constraints":
                defenses["has_prompt_constraints"] = True

    defenses["defense_count"] = sum(
        1 for k, v in defenses.items() if k.startswith("has_") and v
    )
    return defenses


def compute_vulnerability_scores(
    all_nodes: set[str],
    edges: list[tuple[str, str]],
    error_counts: dict[str, int],
    defensive_patterns: dict,
) -> list[dict]:
    """Compute topology-aware vulnerability score per node using Sherlock priors.

    Args:
        all_nodes: Set of all node IDs.
        edges: List of (source, target) edge tuples.
        error_counts: Mapping node_id -> error count across runs.
        defensive_patterns: Defensive patterns dict from scanner.

    Returns:
        List of per-node vulnerability dicts.
    """
    unique_edges = list(set(edges))

    # Compute per-node metrics
    fan_in: dict[str, int] = {}
    fan_out: dict[str, int] = {}
    for src, tgt in unique_edges:
        fan_out[src] = fan_out.get(src, 0) + 1
        fan_in[tgt] = fan_in.get(tgt, 0) + 1

    sources = set(s for s, _ in unique_edges)
    targets = set(t for _, t in unique_edges)

    results: list[dict] = []
    total_nodes = len(all_nodes)

    for nid in all_nodes:
        position = classify_position(nid, sources, targets)
        fi = fan_in.get(nid, 0)
        fo = fan_out.get(nid, 0)

        # Simplified betweenness centrality
        if total_nodes <= 2:
            betweenness = 0.0
        elif position == "intermediate":
            betweenness = min(
                1.0,
                fi * fo / max(1, (total_nodes - 1) * (total_nodes - 2) / 2),
            )
        else:
            betweenness = 0.0

        downstream = compute_downstream_reach(nid, unique_edges)

        # Sherlock-inspired vulnerability scoring
        base_score = 0.3

        # Terminal nodes: 1.5x (accumulate errors)
        if position == "terminal":
            base_score *= 1.5

        # Initial nodes: 1.3x (errors propagate downstream)
        if position == "initial":
            base_score *= 1.3

        # Fan-in multiplier
        if fi > 1:
            base_score *= (1.0 + 0.2 * fi)

        # Error propagation reach
        if downstream > 0:
            base_score *= (1.0 + 0.15 * downstream)

        # Betweenness centrality boost
        base_score *= (1.0 + 0.3 * betweenness)

        vulnerability_score = min(1.0, base_score)

        # Defense reduction
        has_defenses = check_node_defenses(nid, defensive_patterns)
        defense_reduction = 0.0
        if has_defenses.get("has_timeout"):
            defense_reduction += 0.1
        if has_defenses.get("has_output_validation"):
            defense_reduction += 0.15
        if has_defenses.get("has_error_handling"):
            defense_reduction += 0.1

        adjusted_score = max(0.0, vulnerability_score - defense_reduction)

        results.append({
            "node_id": nid,
            "position_class": position,
            "fan_in": fi,
            "fan_out": fo,
            "betweenness_centrality": round(betweenness, 3),
            "error_propagation_reach": downstream,
            "error_count_across_runs": error_counts.get(nid, 0),
            "raw_vulnerability_score": round(vulnerability_score, 3),
            "has_defenses": has_defenses,
            "vulnerability_score": round(adjusted_score, 3),
        })

    return results
